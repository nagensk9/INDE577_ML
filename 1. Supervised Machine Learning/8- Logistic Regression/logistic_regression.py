# -*- coding: utf-8 -*-
"""Logistic Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s0B296U5oc2zBH-xxHyWeJ2fWA2WUjEb

# Logistic Regression

**Overview**
"""

# Import the required libraries for data processing and visualization
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Import the required libraries for machine learning
import math
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

from sklearn.preprocessing import LabelEncoder

# Set the dataset URL
url = "https://raw.githubusercontent.com/nagensk9/INDE577_ML/main/Dataset/Classification/adult.csv"

# Load Data
df = pd.read_csv(url)
df.head()

"""###Data Cleaning"""

# Replace '?' with the mode in workclass, occupation, and native-country columns
df['workclass'].replace('?', df['workclass'].mode()[0], inplace=True)
df['occupation'].replace('?', df['occupation'].mode()[0], inplace=True)
df['native-country'].replace('?', df['native-country'].mode()[0], inplace=True)

# Convert income column to 0/1
df['income'] = df['income'].apply(lambda x: 0 if x == '<=50K' else 1)

# Drop duplicate rows
df.drop_duplicates(inplace=True)

# Map education categories to broader categories
edu_mapping = {
    '1st-4th': 'HS',
    '5th-6th': 'HS',
    '7th-8th': 'HS',
    '9th': 'HS',
    '10th': 'HS',
    '11th': 'HS',
    '12th': 'HS',
    'HS-grad': 'Grad',
    'Assoc-acdm': 'college',
    'Assoc-voc': 'college',
    'Some-college': 'college',
    'Bachelors': 'Bachelors',
    'Masters': 'Masters',
    'Prof-school': 'Masters',
    'Doctorate': 'Doctorate',
}

df['education'] = df['education'].map(edu_mapping)

# Map marital status categories to broader categories
marital_mapping = {
    'Never-married': 'Never_married',
    'Married-civ-spouse': 'Married',
    'Married-spouse-absent': 'Married',
    'Married-AF-spouse': 'Married',
    'Widowed': 'Widowed',
    'Divorced': 'Separated',
    'Separated': 'Separated',
}

df['marital-status'] = df['marital-status'].map(marital_mapping)

# Create a LabelEncoder object
le = LabelEncoder()

# Apply label encoding to every column in the DataFrame
df = df.apply(lambda col: le.fit_transform(col.astype(str)), axis=0)

df.head()

# list of columns to drop
cols_to_drop = ['education', 'native-country', 'income']
# set y as the "predclass" column
y = df['income']

# set X as the dataset with the columns to drop removed
X = df.drop(cols_to_drop, axis=1)

X.head()

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Instantiate the logistic regression model
logreg = LogisticRegression()

# Fit the model on the training data
logreg.fit(X_train, y_train)

# Predict on the test data
y_pred = logreg.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)
print("Confusion Matrix:\n", conf_matrix)

# Confusion Matrix

cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix using seaborn heatmap
sns.set(font_scale=1.4) # adjust font size
sns.heatmap(cm, annot=True, annot_kws={"size": 16}, cmap="Blues", fmt="d") # adjust annotation size and color
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# Predict probabilities for test set
y_score = logreg.predict_proba(X_test)[:, 1]

# Compute ROC curve and AUC
fpr, tpr, _ = roc_curve(y_test, y_score)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

